"""
This module helps generate a poem by using a recurrent neural network. 
After generating the poem, the poem undergoes a cleaning process and also
gets evaluated. 

Author: Dejie Zhen
CSCI 3725
Date: November 22, 2022
"""

import spacy
from django.conf import settings
from .neural_network import Neural_Network
from .evaluator import Evaluator
import enchant
import random
from thefuzz import fuzz
import re
import string

class Poem:
    def __init__(self) -> None:
        """
        A class representing a poem that is generated by a 
        recurrent neural network

        Args:
            none
        """
        self.words_bank = set()
        self.nlp = spacy.load("en_core_web_lg")
        self.dictionary = enchant.Dict("en_US")

    def speech_output(self, request):
        """
        Get speech recognition data from the frontend

        Args:
            request: data from the frontend
        """
        if request.method == "POST":
            data=request.POST.get('speech-output')
            return data

    def fill_bag_of_words(self):
        """
        Populate a word bank with all the words from the input file

        Args:
            none
        """
        text = self.read_file()
        doc = self.nlp(text)
        for token in doc:
            if self.dictionary.check(token.text):
                self.words_bank.add(token.text)

    def read_file(self):
        """
        Read and return input file from static folder

        Args:
            none
        """
        static_folder = settings.STATICFILES_DIRS[0]
        path_to_file = static_folder + "/merged/asian_poems.txt"
        text = open(path_to_file, 'rb').read().decode(encoding='utf-8')
        return text
    
    def word_match(self, token):
        """
        Match word against all the words we found in the text file I trained
        the recurrent neural network on. Swap word if we found an 80% match

        Args:
            token(str): current word
        """
        all_words = list(self.words_bank)
        for words in all_words:
            if fuzz.ratio(words, token) > 80:
                return words

    def delete_last_line(self, poem_list):
        """
        Delete the last line of the poem since it is usually an incomplete line

        Args:
            poem_list(list): initial poem in list form
        """
        last_word_idx = 0
        last_word = ''
        for i in range(len(poem_list)-1, -1, -1):
            if re.search('\n', poem_list[i]):
                splitted_end = poem_list[i].split('\n')
                last_word_idx = i
                last_word = splitted_end[0]
                break
        poem_list[last_word_idx] = last_word
        del poem_list[last_word_idx+1:]
        return poem_list

    # def word_with_newlines(self):

    def clean_poem(self, poem_list):
        """
        Make the poem more readable with word matching and word
        suggestions.

        Args:
            poem_list(list): initial poem in list form
        """
        word_match_cnt = 0
        suggest_word_cnt = 0
        for index, token in enumerate(poem_list):
            if token in string.punctuation \
                or (index > 1 and token == poem_list[index-1]):
                poem_list[index] = ''
                continue

            if index > 1 \
                and index < len(poem_list) \
                and token != '' \
                and not self.dictionary.check(token) \
                and not re.search('\n', token):
                
                word_matched = self.word_match(token)
                if word_matched:
                    poem_list[index] = word_matched
                    word_match_cnt += 1
                else:
                    print(index)
                    try:
                        poem_list[index] = self.dictionary.suggest(token)[0]
                        suggest_word_cnt += 1
                    except:
                        print("No suggested words found")
            # elif index > 10 \
            #     and token != '\n' \
            #     and not self.dictionary.check(token) \
            #     and re.search('\n', token):
                
            #     nline = token.count('\n')
            #     token_list = token.split('\n')
            #     new_words = []
            #     for i, word in enumerate(token_list):
            #         if word == '': 
            #             continue
            #         word_matched = self.word_match(word)
            #         if word_matched:
            #             new_words.append(word_matched)
            #             word_match_cnt += 1
            #         else:
            #             print(index)
            #             try:
            #                 new_words.append(self.dictionary.suggest(word)[0])
            #                 suggest_word_cnt += 1
            #             except:
            #                 print('No suggested words found')

            #     newline_joiner = '\n' * nline
            #     joined_words = newline_joiner.join(new_words)
            #     poem_list[index] = joined_words
     
        poem_list = self.delete_last_line(poem_list)
        return ' '.join(poem_list), word_match_cnt, suggest_word_cnt

    def generate_poem(self, speech_data):
        """
        Generate and clean poem that will be returned and displayed to the 
        frontend 

        Args:
            speech_data(str): data from speech recognition
        """
        self.fill_bag_of_words()
        neural = Neural_Network()

        initial_poem = neural.execute_model(speech_data)
        poem_list = initial_poem.split(' ')

        cleaned_poem, word_match_cnt, suggest_word_cnt = \
            self.clean_poem(poem_list)

        evaluator = Evaluator(initial_poem, cleaned_poem, 
                                word_match_cnt, suggest_word_cnt)
        evaluator.write_metrics()
        return cleaned_poem